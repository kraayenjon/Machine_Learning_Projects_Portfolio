{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook uses the same dataset (automobile.csv) as in the previous threads.\n",
    "\n",
    "The notebook implements a version of Naive Bayes from sklearn library:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB\n",
    "\n",
    "This version works only with categorical features (as is the version we learned in class, which you should review).\n",
    "\n",
    "The first step is to execute the notebook in an environment with access to the automobile.csv file. Read carefully all the comments and the text in the notebook, don't just zap through all the cells. If you do not understand something, you are encouraged to either read about it in some Python/Pandas/sklearn documentation, or to ask in the thread (Do not be shy! You are not graded for your previous knowledge).\n",
    "\n",
    "The last part of the notebook computes training and validation accuracy of a trained Naive Bayes classifier. For some cases, the part that computes the validation accuracy will crash (!!). Please share the accuracies you get in the thread, and if your execution crashes, please share that in the thread as well.\n",
    "\n",
    "If your execution crashed, try to guess why. If it didn't crash, but you want it to crash, try to run again and again (with different splits) until it does.\n",
    "\n",
    "In the next forum we will fix the crash and look more closely at what Naive Bayes can give us.\n",
    "\n",
    "**Advanced:** If you figured out why it crashes, see if you can figure out from the sklearn Naive Bayes documentation how to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kqhu9dCxcoR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKJhAdCJX6qm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"automobile.csv\", na_values = '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sycqIO8Cx9cf"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZ1lm3qpyMv4"
   },
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wzdugg45zqRs"
   },
   "outputs": [],
   "source": [
    "# Let's see the types of the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-e0uSOuZAMG"
   },
   "source": [
    "Target variable is Risk, ranging from -2 to 3.  For this notebook, we will covert it to \"0\" for (-2,-1,0) and \"1\" for (1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAXbX4kAY7CH"
   },
   "outputs": [],
   "source": [
    "df[\"Risk\"] = df[\"Risk\"].apply(lambda x: 0 if x<=0 else 1)\n",
    "df[\"Risk\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1iTpBxH86L3"
   },
   "source": [
    "Let's keep only the categoricals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viAf4ZCPZ5zC"
   },
   "outputs": [],
   "source": [
    "# Take only categoricals\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "categoricals = [c for c in df.columns if ((not is_numeric_dtype(df[c])) or c=='Risk')]\n",
    "df_cat = df[categoricals].astype(str).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## JK: alternative way to select 'obj'\n",
    "df_cat1 = df.select_dtypes(['object'])\n",
    "\n",
    "#changing dtype to 'category'\n",
    "df_cat1 = df_cat1.astype('category')\n",
    "df_cat1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cat1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JK: mfi and spfi are unique values and will crash the model\n",
    "df_cat1['Fuel-system'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1qG-ertFWoq"
   },
   "source": [
    "For Pandas categoricals, a missing value is not a category, it is just a missing value.\n",
    "\n",
    "Let's replace the missing values with a new category \"zzz\".  This way, we are using the information that a value is missing as a category by itself.  As we discussed in class, this may be useful, especially if values are missing \"not at random\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQZnV2uSFViM"
   },
   "outputs": [],
   "source": [
    "def add_dummy_category(series):\n",
    "  series = series.cat.add_categories(['zzz'])\n",
    "  series = series.fillna('zzz')\n",
    "  return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7u8zNrRFsAQ"
   },
   "outputs": [],
   "source": [
    "for c in df_cat.columns: \n",
    "    df_cat[c] = add_dummy_category(df_cat[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### 2 NaN values have been registered as categories so we are not categorizing them as 'zzz'\n",
    "df_cat['Num-of-doors'].value_counts()\n",
    "\n",
    "df_cat[df_cat['Num-of-doors'] == 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat['Num-of-doors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A4WuM7xCLun"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB #Naive Bayes (categorical)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ochrKT3U8j3u"
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(df_cat, train_size=0.7)\n",
    "X_train = train.drop('Risk', axis=1)\n",
    "y_train = train['Risk']\n",
    "X_val = val.drop('Risk', axis=1)\n",
    "y_val = val['Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXvHgWTM7A2q"
   },
   "outputs": [],
   "source": [
    "clf = CategoricalNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##JK: fixing the error to have same number of categories between train/test\n",
    "\n",
    "#clf = CategoricalNB(min_categories=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysVh6vTX73xa"
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvPVwTzD_XC7"
   },
   "source": [
    "Oops, sklearn's categorical naive Bayes' implementation doesn't like string values.  We have to convert all strings to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbTBBoez8xRS"
   },
   "outputs": [],
   "source": [
    "def categorical_to_int(series):\n",
    "  categories = series.cat.categories\n",
    "  categories = categories.sort_values()\n",
    "  return series.replace(to_replace = categories, value = range(len(categories))).astype('string').astype('int32')\n",
    "\n",
    "# see what happens if you try to convert to int32 without first converting to string...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vDCpLrYS_VuX"
   },
   "outputs": [],
   "source": [
    "for c in df_cat.columns: df_cat[c] = categorical_to_int(df_cat[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHdREqpBFMJQ"
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(df_cat, train_size=0.7)\n",
    "X_train = train.drop('Risk', axis=1)\n",
    "y_train = train['Risk']\n",
    "X_val = val.drop('Risk', axis=1)\n",
    "y_val = val['Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRIZNi0PGqsA"
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRcMLXKTHwH9"
   },
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train) # check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aPbJM3OISTs"
   },
   "outputs": [],
   "source": [
    "clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rayHx_MpIioM"
   },
   "source": [
    "In some cases the last line of code crashes.  Can you see why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.nunique())\n",
    "print('')\n",
    "print(y_train.nunique())\n",
    "print('')\n",
    "print(X_val.nunique())\n",
    "print('')\n",
    "print(y_val.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cat_unique = df_cat.nunique()\n",
    "x_train_unique = X_train.nunique()\n",
    "x_val_unique =X_val.nunique()\n",
    "\n",
    "comparing = pd.DataFrame({'df_cat':df_cat_unique, 'x_train': x_train_unique, 'x_val':x_val_unique})#.transpose()\n",
    "comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train['Fuel-system'].value_counts())\n",
    "print(\"\")\n",
    "print(X_val['Fuel-system'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
